<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>cs224n Lecture 13 | Eomiso&#39;s TIL(Today I Learned)</title>
    <meta name="generator" content="VuePress 1.4.1">
    <link rel="icon" href="/TIL/logo.png">
    <meta name="description" content="Write what you have learned today">
    <link rel="preload" href="/TIL/assets/css/0.styles.34c10105.css" as="style"><link rel="preload" href="/TIL/assets/js/app.2722f0f6.js" as="script"><link rel="preload" href="/TIL/assets/js/2.2c4c9c51.js" as="script"><link rel="preload" href="/TIL/assets/js/18.442c0c06.js" as="script"><link rel="prefetch" href="/TIL/assets/js/10.2f8e0e30.js"><link rel="prefetch" href="/TIL/assets/js/11.1ff1a57e.js"><link rel="prefetch" href="/TIL/assets/js/12.15c40c13.js"><link rel="prefetch" href="/TIL/assets/js/13.7bf652e1.js"><link rel="prefetch" href="/TIL/assets/js/14.c9414a20.js"><link rel="prefetch" href="/TIL/assets/js/15.2d01f370.js"><link rel="prefetch" href="/TIL/assets/js/16.0d89dffe.js"><link rel="prefetch" href="/TIL/assets/js/17.07c38e4d.js"><link rel="prefetch" href="/TIL/assets/js/19.1b5bf633.js"><link rel="prefetch" href="/TIL/assets/js/20.86bba05d.js"><link rel="prefetch" href="/TIL/assets/js/21.e544340d.js"><link rel="prefetch" href="/TIL/assets/js/22.65a2edf5.js"><link rel="prefetch" href="/TIL/assets/js/23.8b174a85.js"><link rel="prefetch" href="/TIL/assets/js/24.64fc03d5.js"><link rel="prefetch" href="/TIL/assets/js/25.ce0ae723.js"><link rel="prefetch" href="/TIL/assets/js/26.8b8ee881.js"><link rel="prefetch" href="/TIL/assets/js/27.bf8c97e7.js"><link rel="prefetch" href="/TIL/assets/js/28.142e3c12.js"><link rel="prefetch" href="/TIL/assets/js/29.81bd0da5.js"><link rel="prefetch" href="/TIL/assets/js/3.313ef446.js"><link rel="prefetch" href="/TIL/assets/js/30.359dbc7f.js"><link rel="prefetch" href="/TIL/assets/js/31.0727ec46.js"><link rel="prefetch" href="/TIL/assets/js/32.fe1c9148.js"><link rel="prefetch" href="/TIL/assets/js/33.a56a58e6.js"><link rel="prefetch" href="/TIL/assets/js/34.27b6efed.js"><link rel="prefetch" href="/TIL/assets/js/35.62f50cfb.js"><link rel="prefetch" href="/TIL/assets/js/36.87dcc99f.js"><link rel="prefetch" href="/TIL/assets/js/37.0e07a91e.js"><link rel="prefetch" href="/TIL/assets/js/38.205eff79.js"><link rel="prefetch" href="/TIL/assets/js/39.aaa60523.js"><link rel="prefetch" href="/TIL/assets/js/4.b761c68e.js"><link rel="prefetch" href="/TIL/assets/js/40.6b01a59c.js"><link rel="prefetch" href="/TIL/assets/js/41.1eb27f61.js"><link rel="prefetch" href="/TIL/assets/js/42.6841e3f3.js"><link rel="prefetch" href="/TIL/assets/js/43.de455827.js"><link rel="prefetch" href="/TIL/assets/js/5.a3718665.js"><link rel="prefetch" href="/TIL/assets/js/6.13ab33a4.js"><link rel="prefetch" href="/TIL/assets/js/7.d95456ce.js"><link rel="prefetch" href="/TIL/assets/js/8.8630e26e.js"><link rel="prefetch" href="/TIL/assets/js/9.1c63a592.js">
    <link rel="stylesheet" href="/TIL/assets/css/0.styles.34c10105.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/TIL/" class="home-link router-link-active"><!----> <span class="site-name">Eomiso's TIL(Today I Learned)</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/eomiso" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://eomiso.blogspot.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Blog
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/eomiso" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://eomiso.blogspot.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Blog
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>1. Python</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>2. Git</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>3. Java</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>4. C++</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>5. Machine Learning</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/TIL/ML/cssn224_1.html" class="sidebar-link">CSS224n Lecture 12</a></li><li><a href="/TIL/ML/cssn224_2.html" class="sidebar-link">CS224n 6강</a></li><li><a href="/TIL/ML/cs224n_3.html" class="sidebar-link">cs224n Lecture 8</a></li><li><a href="/TIL/ML/cs224n_4.html" class="active sidebar-link">cs224n Lecture 13</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#개요" class="sidebar-link">개요</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#unknown-words" class="sidebar-link">Unknown words</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#taglm-cove" class="sidebar-link">TagLM, CoVe</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#elmo-embeddings-from-language-models" class="sidebar-link">ELMo : Embeddings from Language Models</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#snli-srl-coref-ner-sst-5" class="sidebar-link">SNLI, SRL, Coref, NER, SST-5</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#ulmfit-transfer-learning" class="sidebar-link">ULMfit, transfer learning</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#transformer" class="sidebar-link">Transformer</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#layer-normalization" class="sidebar-link">Layer normalization</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#positional-encoding-segment-embedding" class="sidebar-link">Positional encoding, segment embedding</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#bert-gpt" class="sidebar-link">BERT, GPT</a></li><li class="sidebar-sub-header"><a href="/TIL/ML/cs224n_4.html#bookcorpus-glue" class="sidebar-link">BookCorpus, GLUE</a></li></ul></li><li><a href="/TIL/ML/cs224n_5.html" class="sidebar-link">cs224n Lecture 14</a></li><li><a href="/TIL/ML/cs224n_6.html" class="sidebar-link">cs224n 10강 정리</a></li><li><a href="/TIL/ML/cs224n_7.html" class="sidebar-link">cs224n lecture 15</a></li><li><a href="/TIL/ML/ml_dict.html" class="sidebar-link">Machine Learning 용어 사전</a></li><li><a href="/TIL/ML/style_transfer.html" class="sidebar-link">Style Transfer from Non-Parallel Text by Cross-Alignment 리뷰</a></li><li><a href="/TIL/ML/using_bert.html" class="sidebar-link">Bert 사용기</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>6. Computer Structure</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Mics.</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="cs224n-lecture-13"><a href="#cs224n-lecture-13" class="header-anchor">#</a> cs224n Lecture 13</h1> <p>부제 : Machine Learning이라는 새로운 task와 sequence-to-sequence 라는 새로운 <strong>architecture</strong></p> <h2 id="개요"><a href="#개요" class="header-anchor">#</a> 개요</h2> <ul><li>Unknown words</li> <li>TagLM, CoVe</li> <li>ELMo</li> <li>SNLI, SRL, Coref, NER, SST-5</li> <li>ULMfit, transfer learning</li> <li>Transformer</li> <li>Multi-head attention</li> <li>Layer normalization</li> <li>Positional encoding, segment embedding</li> <li>BERT, GPT</li> <li>BookCorpus, GLUE</li></ul> <h2 id="unknown-words"><a href="#unknown-words" class="header-anchor">#</a> Unknown words</h2> <p>지금까지는 one representation of words 만 있다고 가정했다(Word2vec, Glove, fastText).<br>
Pre-Trained word vectors 를 사용하는 것이 1~2%정도 성능을 개선하는 것으로 나타났다. Pre-Trained word vectors 를 가지고 추가적으로 Unknown 단어들을 un supervised learning으로  학습하면 되는 것이다.</p> <p>또는 그냥 랜덤 벡터를 넣기도 한다. 각 단어는 꼭 하나의 벡터와 매핑이 되도록 해주는 것이다.</p> <div class="custom-block tip"><p class="custom-block-title">Tip from Manning regarding unknown words.</p> <p>Train Time : Vocab is {words occurring, say, &gt;= 5times} + {<UNK>}
Map all rarer words (&lt;5) to <UNK>, train a word vector for it.
Runtime : use <UNK> when out-of-vocabulary(OOV) words occur</UNK></UNK></UNK></p></div> <p>그런데 이렇게 하면 서로 다른 단어였던 UNK words 들을 구분할 수 없다는 문제가 있다(identity나 meaning 차원에서).<br>
그래서 char-level models 를 이용해서 vector를 만드는 것이 좋다!</p> <p>Unknown vocab이 나왔을 때, 인코더에서 봤던 단어를 가져오는 경우도 있다.</p> <p>어쨌거나 이 방법은 word-sense를 정확히 반영하지 못한다. Context를 반영하지 못한다는 것(star- universe, hollywood senses).</p> <h2 id="taglm-cove"><a href="#taglm-cove" class="header-anchor">#</a> TagLM, CoVe</h2> <p>그런데 LSTM 모델을 생각해보면 context-specific word representations를 매 position 마다 잘 산출하는 것을 확인할 수 있다.
<img src="/TIL/ML/13_LSTM.png" alt=""></p> <p>일단 word에 context를 가미하고 싶고, standardly learn task RNN only on small task-labeled data 라는 한계를 극복하고자 하는 시도다.<br>
이를 위해서 NLM을 unlabeled corpus 에 학습시키는 semi-supervised approach를 해보자는 것.</p> <p><img src="/TIL/ML/13_TagLM1.png" alt=""> <img src="/TIL/ML/13_TagLM2.png" alt=""></p> <p>아무튼 Peters et al.(2017) 논문이 밝혀낸 것은 1) bidirectional LM이 only forward 보다 도움이 된다는 것과, 2) supervised data를 학습한 LM은 도움이 되지 않는다는 것, 3) 큰 LM 을 가지는게 적은 모델에 대해 도움이 된다(Q. <strong>ppl 30 이 무슨 의미지?</strong> ).</p> <p>Cove 모델은 매닝 성님이 그냥 skip 해버렸다.</p> <h2 id="elmo-embeddings-from-language-models"><a href="#elmo-embeddings-from-language-models" class="header-anchor">#</a> ELMo : Embeddings from Language Models</h2> <p>Peters etal.(2018)
TagLM의 업글 버전, Bi-NLM을 학습하고 그 모든 Layer을 prediction에 활용해라.<br>
별로 크지 않은 LM을 활용하고자 한다. character CNN을 활용해서 initial word representation 을 뽑아내는데 이를 통해 parameter의 개수를 줄인다.<br> <strong>residual connection</strong> 을 사용한다.
2개의 biLSTM Layer을 활용
Input 과 Output(softmax) token의 parameter를 묶고 (parameter를 묶는 다는게 뭐지?? concat 한다는 것인가?) 이렇게 묶인 것을 forward와 backward LM 사이에 묶는다.</p> <h2 id="snli-srl-coref-ner-sst-5"><a href="#snli-srl-coref-ner-sst-5" class="header-anchor">#</a> SNLI, SRL, Coref, NER, SST-5</h2> <p>Stanfor Natural Language Inference : 추론(contradiction, neutral, entailment)
Semantic Role Labeling :
나머지는 대충 무엇인지 다 알고 있는 것들</p> <ul><li>CoLa : corpus of Linguistics Acceptability(Warstadt et al., 2018) consists of English acceptability judgements frawn from books and journal articles on linguistic theory. Each example is a sequence of words annotated with whether it is a grammatical English sentence.</li></ul> <h2 id="ulmfit-transfer-learning"><a href="#ulmfit-transfer-learning" class="header-anchor">#</a> ULMfit, transfer learning</h2> <p>Universal Language Model Fine-tuning
LM 에서 학습 정보를 활용하려고 한다는 점에서는 ELMO와 동일하다.
LM 에서 학습된 네트워크를 그대로 활용한다.</p> <p><img src="/TIL/ML/13_ULMdfit.png" alt=""></p> <h2 id="transformer"><a href="#transformer" class="header-anchor">#</a> Transformer</h2> <h3 id="basic-blocks"><a href="#basic-blocks" class="header-anchor">#</a> Basic blocks</h3> <blockquote><p>Dot-product Attention
Scaled Dot-product Attention
Self-attention at the encoder</p></blockquote> <h3 id="multi-head-attention"><a href="#multi-head-attention" class="header-anchor">#</a> Multi-head attention</h3> <h3 id="encoder"><a href="#encoder" class="header-anchor">#</a> Encoder</h3> <h3 id="decoder"><a href="#decoder" class="header-anchor">#</a> Decoder</h3> <h3 id="tips-and-tricks-of-tranformer"><a href="#tips-and-tricks-of-tranformer" class="header-anchor">#</a> Tips and Tricks of Tranformer</h3> <h2 id="layer-normalization"><a href="#layer-normalization" class="header-anchor">#</a> Layer normalization</h2> <h2 id="positional-encoding-segment-embedding"><a href="#positional-encoding-segment-embedding" class="header-anchor">#</a> Positional encoding, segment embedding</h2> <h2 id="bert-gpt"><a href="#bert-gpt" class="header-anchor">#</a> BERT, GPT</h2> <p>BERT : Bidirectional Encoder Representations from Transformers</p> <p><strong>&quot;Words can see themselves&quot;</strong> :</p> <h2 id="bookcorpus-glue"><a href="#bookcorpus-glue" class="header-anchor">#</a> BookCorpus, GLUE</h2></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">6/12/2020, 1:46:49 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/TIL/ML/cs224n_3.html" class="prev">
        cs224n Lecture 8
      </a></span> <span class="next"><a href="/TIL/ML/cs224n_5.html">
        cs224n Lecture 14
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/TIL/assets/js/app.2722f0f6.js" defer></script><script src="/TIL/assets/js/2.2c4c9c51.js" defer></script><script src="/TIL/assets/js/18.442c0c06.js" defer></script>
  </body>
</html>
