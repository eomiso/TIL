(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{352:function(t,a,i){"use strict";i.r(a);var s=i(20),e=Object(s.a)({},(function(){var t=this,a=t.$createElement,i=t._self._c||a;return i("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[i("h1",{attrs:{id:"cs224n-lecture-15"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#cs224n-lecture-15"}},[t._v("#")]),t._v(" cs224n lecture 15")]),t._v(" "),i("h2",{attrs:{id:"개요"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#개요"}},[t._v("#")]),t._v(" 개요")]),t._v(" "),i("ul",[i("li",[t._v("Natural Language Generation")]),t._v(" "),i("li",[t._v("large beam size")]),t._v(" "),i("li",[t._v("Persona")]),t._v(" "),i("li",[t._v("Sampling-based decoding")]),t._v(" "),i("li",[t._v("Gigaword, LCSTS, NYT, CNN/DailyMail, Wikihow")]),t._v(" "),i("li",[t._v("Simple Wikipedia, Newsela")]),t._v(" "),i("li",[t._v("Extractive vs. abstractive summarization")]),t._v(" "),i("li",[t._v("tf-idf")]),t._v(" "),i("li",[t._v("ROUGE")]),t._v(" "),i("li",[t._v("Pointer-Generator Networks")]),t._v(" "),i("li",[t._v("Reinforcement Learning")]),t._v(" "),i("li",[t._v("Mutual information")]),t._v(" "),i("li",[t._v("Retrieve-and-refine model")]),t._v(" "),i("li",[t._v("Skip-thought vectors")]),t._v(" "),i("li",[t._v("METEOR")]),t._v(" "),i("li",[t._v("Twitter, Ubuntu")]),t._v(" "),i("li",[t._v("humanness vs. conversational quality")]),t._v(" "),i("li",[t._v("Teacher forcing")])]),t._v(" "),i("p",[t._v("NLG 에 대한 전반적인 내용과 decoding 알고리즘, NLG task 와 그에 대한 neural approaches. NLG evaluation a tricky situation. NLG cutting edge research trends.")]),t._v(" "),i("h2",{attrs:{id:"natural-language-generation"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#natural-language-generation"}},[t._v("#")]),t._v(" Natural Language Generation")]),t._v(" "),i("p",[t._v("Any setting in which we generate new text (e.g. decoder)\nNLG 는 machine translation, summarization, dialogue, creative writing, freefrom question answering(answer is generated, not extracted - different from squad), Image captioning 의 subcomponent 들이다.")]),t._v(" "),i("p",[t._v("참고로 Language Momdeling은 다음 단어를 예측하는 모델이다.(given words so far) $$ P(y_t|y_1, \\ldots, y_{t-1} ) $$\n해서 이러한 probability distribution 을 생성하는 시스템을 Language Momdel이라고 한다.")]),t._v(" "),i("p",[i("strong",[t._v("Conditional Language Modeling")]),t._v(" : the task of predicting the next word, given the words so far, and "),i("em",[t._v("also some other input")]),t._v(" "),i("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[i("mjx-math",{staticClass:" MJX-TEX"},[i("mjx-mi",{staticClass:"mjx-i"},[i("mjx-c",{attrs:{c:"x"}})],1)],1)],1),t._v(" "),i("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[i("mjx-math",{staticClass:" MJX-TEX"},[i("mjx-mi",{staticClass:"mjx-i"},[i("mjx-c",{attrs:{c:"P"}})],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:"("}})],1),i("mjx-msub",[i("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[i("mjx-c",{attrs:{c:"y"}})],1),i("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[i("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[i("mjx-c",{attrs:{c:"t"}})],1)],1)],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:"|"}})],1),i("mjx-msub",[i("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[i("mjx-c",{attrs:{c:"y"}})],1),i("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[i("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[i("mjx-c",{attrs:{c:"1"}})],1)],1)],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:","}})],1),i("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[i("mjx-c",{attrs:{c:"2026"}})],1),i("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[i("mjx-c",{attrs:{c:","}})],1),i("mjx-msub",{attrs:{space:"2"}},[i("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[i("mjx-c",{attrs:{c:"y"}})],1),i("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[i("mjx-TeXAtom",{attrs:{size:"s"}},[i("mjx-mi",{staticClass:"mjx-i"},[i("mjx-c",{attrs:{c:"t"}})],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:"2212"}})],1),i("mjx-mn",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:","}})],1),i("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[i("mjx-c",{attrs:{c:"x"}})],1),i("mjx-mo",{staticClass:"mjx-n"},[i("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),i("ul",[i("li",[t._v("large beam size")]),t._v(" "),i("li",[t._v("Persona")]),t._v(" "),i("li",[t._v("Sampling-based decoding")]),t._v(" "),i("li",[t._v("Gigaword, LCSTS, NYT, CNN/DailyMail, Wikihow")]),t._v(" "),i("li",[t._v("Simple Wikipedia, Newsela")]),t._v(" "),i("li",[t._v("Extractive vs. abstractive summarization")]),t._v(" "),i("li",[t._v("tf-idf")]),t._v(" "),i("li",[t._v("ROUGE")]),t._v(" "),i("li",[t._v("Pointer-Generator Networks")]),t._v(" "),i("li",[t._v("Reinforcement Learning")]),t._v(" "),i("li",[t._v("Mutual information")]),t._v(" "),i("li",[t._v("Retrieve-and-refine model")]),t._v(" "),i("li",[t._v("Skip-thought vectors")]),t._v(" "),i("li",[t._v("METEOR")]),t._v(" "),i("li",[t._v("Twitter, Ubuntu")]),t._v(" "),i("li",[t._v("humanness vs. conversational quality")]),t._v(" "),i("li",[t._v("Teacher forcing")])])])}),[],!1,null,null,null);a.default=e.exports}}]);